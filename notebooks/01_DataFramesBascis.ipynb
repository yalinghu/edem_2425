{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3WKxUMvQ9JW"
      },
      "source": [
        "# DataFrames Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBsRl4yARA3x"
      },
      "source": [
        "## Prerrequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KID1ObYRDA4"
      },
      "source": [
        "Install Spark and Java in VM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9EjQzqhRJSZ",
        "outputId": "6219216a-bbc2-445a-98e4-ebdfffebaf8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-11-26 09:19:40--  https://dlcdn.apache.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400864419 (382M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.5.3-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.5.3-bin-had 100%[===================>] 382.29M   252MB/s    in 1.5s    \n",
            "\n",
            "2024-11-26 09:19:53 (252 MB/s) - ‘spark-3.5.3-bin-hadoop3.tgz’ saved [400864419/400864419]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# install Java8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# download spark 3.5.3\n",
        "!wget /q https://dlcdn.apache.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4s6wcUsSPHQ",
        "outputId": "c35bb9d3-692d-45a8-9238-dee092febe8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 391476\n",
            "drwxr-xr-x 1 root root      4096 Nov 22 14:23 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root 400864419 Sep  9 05:35 spark-3.5.3-bin-hadoop3.tgz\n"
          ]
        }
      ],
      "source": [
        "ls -l # check the .tgz is there"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSA_T2q7SEt_"
      },
      "outputs": [],
      "source": [
        "# unzip it\n",
        "!tar xf spark-3.5.3-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpKEfJTeii2Y"
      },
      "outputs": [],
      "source": [
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwH-zC17SGnP",
        "outputId": "43249bd4-34b0-4206-d202-7258c2d55def"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n",
            "Requirement already satisfied: folium in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from folium) (0.8.0)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from folium) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from folium) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from folium) (2.32.3)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.10/dist-packages (from folium) (2024.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9->folium) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (2024.8.30)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install py4j\n",
        "\n",
        "# For maps\n",
        "!pip install folium\n",
        "!pip install plotly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1tk452JRjuY"
      },
      "source": [
        "Define the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrMxCiuZRl7h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--master local[*] pyspark-shell\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk_3rL02Q9JZ"
      },
      "source": [
        "Start Spark Session\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-HtQz6mfQ9JZ",
        "outputId": "0c57b1da-271f-46a5-ed68-9d4cfad916f1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.5.3'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import findspark\n",
        "findspark.init(\"spark-3.5.3-bin-hadoop3\")# SPARK_HOME\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# create the session\n",
        "spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .appName(\"DataFrames Basics\") \\\n",
        "        .master(\"local[*]\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "spark.version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "DrOjmfL9Q9Ja",
        "outputId": "5de332d9-3fb6-4f7d-bef1-8d59144746be"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://f24f1c97ffbe:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>DataFrames Basics</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7952d240a3b0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBZ8ufPAQ9Jb"
      },
      "outputs": [],
      "source": [
        "# For Pandas conversion optimization\n",
        "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJ-cdrAlQ9Jb"
      },
      "outputs": [],
      "source": [
        "# Import sql functions\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIP7U3YYTDbw"
      },
      "source": [
        "Download datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d63cazZLTKTv",
        "outputId": "d89993b1-1b3a-4959-c0bf-e2bcaf4bc3fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bank.csv  cars.json  movies.json  vehicles.csv\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p dataset\n",
        "!wget -q https://raw.githubusercontent.com/paponsro/spark_edem_2324/master/dataset/cars.json -P /dataset\n",
        "!wget -q https://raw.githubusercontent.com/paponsro/spark_edem_2324/master/dataset/movies.json -P /dataset\n",
        "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/bank.csv -P /dataset\n",
        "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/vehicles.csv -P /dataset\n",
        "!ls /dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml1O2OiQU6ah",
        "outputId": "2e1dcaae-a7e3-4665-becd-a4d948e73671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 1784\n",
            "-rw-r--r-- 1 root root  461474 Nov 26 09:25 bank.csv\n",
            "-rw-r--r-- 1 root root   74910 Nov 26 09:25 cars.json\n",
            "-rw-r--r-- 1 root root 1274347 Nov 26 09:25 movies.json\n",
            "-rw-r--r-- 1 root root    4370 Nov 26 09:25 vehicles.csv\n"
          ]
        }
      ],
      "source": [
        "ls -l /dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94aRTBiPQ9Jc"
      },
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxXiDT4XUgjl"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import Row\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p69TjjJBTrDF",
        "outputId": "5847bc9d-eda8-4a47-e2fd-7c77d0d388fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------+-------+---------+-------+\n",
            "|age|       job|marital|education|balance|\n",
            "+---+----------+-------+---------+-------+\n",
            "| 30|unemployed|married|  primary|   1787|\n",
            "| 33|  services|married|secondary|   4789|\n",
            "| 35|management| single| tertiary|   1350|\n",
            "+---+----------+-------+---------+-------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "bankText = spark.sparkContext.textFile(\"/dataset/bank.csv\")\n",
        "\n",
        "#we have to: remove first row (headers), map the rest, and create DF\n",
        "bank = bankText.map(lambda lineaCsv: lineaCsv.split(\";\"))\\\n",
        ".filter(lambda s: s[0] != \"\\\"age\\\"\") \\\n",
        ".map(lambda row: Row(int(row[0]), row[1].replace(\"\\\"\", \"\"), row[2].replace(\"\\\"\", \"\"), row[3].replace(\"\\\"\", \"\"), row[5].replace(\"\\\"\", \"\"))) \\\n",
        ".toDF([\"age\", \"job\", \"marital\", \"education\", \"balance\"]) \\\n",
        ".withColumn(\"age\", col(\"age\").cast(\"int\"))\n",
        "\n",
        "bank.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnCG9XHsTUfe"
      },
      "source": [
        "Read directly from JSON file to a DF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBWBcsLDTYuF"
      },
      "outputs": [],
      "source": [
        "carsDF = spark.read.option(\"inferSchema\", True).json(\"/dataset/cars.json\") # inferSchema requires one extra pass over the data\n",
        "\n",
        "# if None is set, it uses de default value (default = False) you can also pass the schema manually"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beN35oUrUo4c"
      },
      "source": [
        "Read directly from csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaxDO13vUlSs",
        "outputId": "4a3b1693-bb94-4781-c8bf-fbc71ee6f620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "|age|       job|marital|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
            "+---+----------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "| 30|unemployed|married|  primary|     no|   1787|     no|  no|cellular| 19|  oct|      79|       1|   -1|       0| unknown| no|\n",
            "| 33|  services|married|secondary|     no|   4789|    yes| yes|cellular| 11|  may|     220|       1|  339|       4| failure| no|\n",
            "| 35|management| single| tertiary|     no|   1350|    yes|  no|cellular| 16|  apr|     185|       1|  330|       1| failure| no|\n",
            "+---+----------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "bankDF = spark.read.option(\"header\", \"true\").option(\"delimiter\", \";\").csv(\"/dataset/bank.csv\")\n",
        "bankDF.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOt52pbaQ9Jc"
      },
      "source": [
        "Showing a DF and print schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmmsrRxaQ9Jd",
        "outputId": "6e68ecf8-64af-4b6b-d51e-c0561a8279bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+\n",
            "|Acceleration|Cylinders|Displacement|Horsepower|Miles_per_Gallon|                Name|Origin|Weight_in_lbs|      Year|\n",
            "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+\n",
            "|        12.0|        8|       307.0|       130|            18.0|chevrolet chevell...|   USA|         3504|1970-01-01|\n",
            "|        11.5|        8|       350.0|       165|            15.0|   buick skylark 320|   USA|         3693|1970-01-01|\n",
            "+------------+---------+------------+----------+----------------+--------------------+------+-------------+----------+\n",
            "only showing top 2 rows\n",
            "\n",
            "root\n",
            " |-- Acceleration: double (nullable = true)\n",
            " |-- Cylinders: long (nullable = true)\n",
            " |-- Displacement: double (nullable = true)\n",
            " |-- Horsepower: long (nullable = true)\n",
            " |-- Miles_per_Gallon: double (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Origin: string (nullable = true)\n",
            " |-- Weight_in_lbs: long (nullable = true)\n",
            " |-- Year: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "carsDF.show(2)\n",
        "carsDF.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij4TDMZ0lkBZ"
      },
      "source": [
        "Get Rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB06W84wlnlY",
        "outputId": "1836f7cc-e790-4121-f52f-b79db7d90984"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Row(Acceleration=12.0, Cylinders=8, Displacement=307.0, Horsepower=130, Miles_per_Gallon=18.0, Name='chevrolet chevelle malibu', Origin='USA', Weight_in_lbs=3504, Year='1970-01-01'),\n",
              " Row(Acceleration=11.5, Cylinders=8, Displacement=350.0, Horsepower=165, Miles_per_Gallon=15.0, Name='buick skylark 320', Origin='USA', Weight_in_lbs=3693, Year='1970-01-01')]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "carsDF.take(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z89eHF1aQ9Jd"
      },
      "source": [
        "Count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtFilGlZWGyo",
        "outputId": "dc282036-be6a-44ae-c00d-e5f452b94def"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "406"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "carsDF.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akmA70EPQ9Jd"
      },
      "source": [
        "Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp6hKanzQ9Je",
        "outputId": "bc6505af-f518-48b0-d699-6f7007c329b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pyspark.sql.types.StructType'>\n",
            "StructType([StructField('Acceleration', DoubleType(), True), StructField('Cylinders', LongType(), True), StructField('Displacement', DoubleType(), True), StructField('Horsepower', LongType(), True), StructField('Miles_per_Gallon', DoubleType(), True), StructField('Name', StringType(), True), StructField('Origin', StringType(), True), StructField('Weight_in_lbs', LongType(), True), StructField('Year', StringType(), True)])\n"
          ]
        }
      ],
      "source": [
        "# obtain a schema\n",
        "carsSchema = carsDF.schema\n",
        "print(type(carsSchema))\n",
        "print(carsSchema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_XS0vB0Q9Je"
      },
      "source": [
        "Custom Schemas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekQkJLT8Q9Je"
      },
      "outputs": [],
      "source": [
        "example = spark.sparkContext.parallelize([(\"chevrolet chevelle malibu\",18,\"1970-01-01\",\"USA\"),\n",
        "    (\"buick skylark 320\",15,\"1970-01-01\",\"USA\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUzjX4kTQ9Je",
        "outputId": "fff60b32-7b11-4766-b2e8-01c56343fbb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- _1: string (nullable = true)\n",
            " |-- _2: long (nullable = true)\n",
            " |-- _3: string (nullable = true)\n",
            " |-- _4: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "exampleDF = spark.createDataFrame(example)\n",
        "exampleDF.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfAtq2qVMsWP",
        "outputId": "af5f7aff-c65c-4b6d-c577-7a08d39510a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+---+----------+---+\n",
            "|                  _1| _2|        _3| _4|\n",
            "+--------------------+---+----------+---+\n",
            "|chevrolet chevell...| 18|1970-01-01|USA|\n",
            "|   buick skylark 320| 15|1970-01-01|USA|\n",
            "+--------------------+---+----------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "exampleDF.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeTtjRirQ9Je"
      },
      "source": [
        "With columns names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhY-f3j1Q9Jf"
      },
      "outputs": [],
      "source": [
        "names = list([\"name\", \"weight\", \"date\", \"country\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqxqPyr1Q9Jf",
        "outputId": "e2bd1064-7f61-4d7d-de33-76f4f396fed4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- weight: long (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example2DF = example.toDF(names)\n",
        "example2DF.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMHUSFgTMxe6",
        "outputId": "ad009ba8-6825-4306-b7dc-04ed0b441cc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+------+----------+-------+\n",
            "|                name|weight|      date|country|\n",
            "+--------------------+------+----------+-------+\n",
            "|chevrolet chevell...|    18|1970-01-01|    USA|\n",
            "|   buick skylark 320|    15|1970-01-01|    USA|\n",
            "+--------------------+------+----------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example2DF.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toUIbosSQ9Jf"
      },
      "outputs": [],
      "source": [
        "# importing sql types\n",
        "from pyspark.sql.types import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZNfLhFWQ9Jf"
      },
      "outputs": [],
      "source": [
        "# custom schema\n",
        "customSchema = StructType([ \\\n",
        "    StructField('name', StringType(), True), \\\n",
        "    StructField('weight', StringType(), True), \\\n",
        "    StructField('date', StringType(), True), \\\n",
        "    StructField('country', StringType(), True)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x63bbTDYQ9Jf",
        "outputId": "a2d5ea7d-f2ad-436f-9836-63fd8d1d9de8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- weight: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example3DF = spark.createDataFrame(example, customSchema)\n",
        "example3DF.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRiqa-G5Q9Jf",
        "outputId": "b94ae71c-e7fe-4021-bd5e-13f0e13b27fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------------+------+----------+-------+\n",
            "|name                     |weight|date      |country|\n",
            "+-------------------------+------+----------+-------+\n",
            "|chevrolet chevelle malibu|18    |1970-01-01|USA    |\n",
            "|buick skylark 320        |15    |1970-01-01|USA    |\n",
            "+-------------------------+------+----------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example3DF.show(2, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3qToymLQ9Jg"
      },
      "outputs": [],
      "source": [
        "# we can also specify schema with DDL (Data Definition Language)\n",
        "customSchema2 = \"`name` STRING NOT NULL, `weight` INT, `date` STRING, `country` STRING\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k9X1gSSQ9Jg",
        "outputId": "7efb3b2b-6d48-4d5d-9a17-c67146e52f77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- name: string (nullable = false)\n",
            " |-- weight: integer (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example4DF = spark.createDataFrame(example, customSchema2)\n",
        "example4DF.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5rayh3uQ9Jg",
        "outputId": "5d10c875-9e14-416f-8e10-4a38ce8cd749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'int'>\n",
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "print(type(example2DF.collect()[0][\"weight\"]))\n",
        "print(type(example3DF.collect()[0][\"weight\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QnciaoWQ9Jg"
      },
      "source": [
        "## Exercises\n",
        "1) Create a manual DF describing smartphones\n",
        "  - maker\n",
        "  - model\n",
        "  - screen dimension\n",
        "  - camera megapixels\n",
        "  \n",
        "2) Read another file from the dataset/ folder, e.g. movies.json\n",
        "  - print its schema\n",
        "  - count the number of rows, call count()\n",
        "\n",
        "3) Take a look to vehicles.csv. Read the file to a DF but this time with your own schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQR1cduXQ9Jg"
      },
      "source": [
        "Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zmg5kbOpl-s3"
      },
      "source": [
        "Exercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAqADV5jW00d"
      },
      "source": [
        "Exercise 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JD2KQtXiYmVn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "ff1af5cda0bea4fe5c4ebc1f94ab9f13d8998f98d08e16d8aba48673b9d00116"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
